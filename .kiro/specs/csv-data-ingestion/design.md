<!--
╔══════════════════════════════════════════════════════════════════════════════╗
║  📚 KIRO 学習ガイド: CSV取り込み機能の設計書                                 ║
╠══════════════════════════════════════════════════════════════════════════════╣
║                                                                              ║
║  このファイルはイベント駆動アーキテクチャの設計サンプルです。                ║
║                                                                              ║
║  アーキテクチャパターン:                                                     ║
║  S3 → S3 Event → Lambda → DynamoDB                                          ║
║                    ↓                                                         ║
║              CloudWatch Logs                                                 ║
║                                                                              ║
║  serverless-weather-system との比較:                                         ║
║  - メイン: CloudFront → API Gateway → Lambda → DynamoDB                     ║
║  - CSV: S3 Event → Lambda → DynamoDB                                        ║
║                                                                              ║
║  学習ポイント:                                                               ║
║  - S3イベントトリガーの設計パターン                                          ║
║  - バッチ処理のエラーハンドリング戦略                                        ║
║  - プロパティの統合と最適化                                                  ║
║                                                                              ║
║  詳細: KIRO_LEARNING.md の「4. Spec駆動開発」を参照                          ║
╚══════════════════════════════════════════════════════════════════════════════╝
-->

# 設計書

## 概要

CSVデータ取り込み機能は、管理者がS3バケットにweather.csvファイルをアップロードすることで、天気データを自動的にDynamoDBに取り込むサーバーレスシステムです。この機能は既存の天気システムと統合され、S3イベントトリガーによってLambda関数を実行し、CSVファイルを解析してデータベースに保存します。

## アーキテクチャ

システムは以下のAWSサービスを使用したイベント駆動アーキテクチャを採用します：

```
S3 Bucket (CSV Upload) → S3 Event → Lambda Function → DynamoDB Table
                                         ↓
                                   CloudWatch Logs
```

### 主要コンポーネント：
1. **S3バケット**: CSVファイルのアップロード先
2. **Lambda関数**: CSV処理とデータ変換を実行
3. **DynamoDB**: 既存の天気データテーブル
4. **CloudWatch**: ログとモニタリング

## コンポーネントとインターフェース

### CSV Ingestion Lambda Function
- **入力**: S3イベント（バケット名、オブジェクトキー）
- **出力**: HTTP レスポンス（ステータスコード、処理結果）
- **責任**: 
  - S3からCSVファイルを読み取り
  - CSVデータの解析と検証
  - DynamoDBへのデータ書き込み
  - エラーハンドリングとログ記録

### S3 Event Trigger
- **トリガー条件**: `.csv`ファイルのPUTイベント
- **設定**: 特定のプレフィックス（例：`weather-data/`）でフィルタリング

### DynamoDB Integration
- **テーブル**: 既存の天気データテーブル
- **操作**: `put_item`による個別レコード挿入
- **項目構造**: CityId, CityName, WeatherName, RainfallProbability

## データモデル

### CSV入力形式（ヘッダーなし）
```
フィールド位置 | データ型 | 説明
0           | int     | CityId（都市ID）
1           | string  | CityName（都市名）
2           | int     | WeatherId（天気ID、使用しない）
3           | string  | WeatherName（天気名）
4           | int     | RainfallProbability（降水確率）
```

### DynamoDB項目構造
```python
{
    'CityId': int,           # 都市の一意識別子
    'CityName': str,         # 都市名（日本語）
    'WeatherName': str,      # 天気タイプ（晴れ、くもり、雨）
    'RainfallProbability': int  # 降水確率（0-100）
}
```

## 正確性プロパティ

*プロパティとは、システムの全ての有効な実行において真であるべき特性や動作です。これは人間が読める仕様と機械で検証可能な正確性保証の橋渡しとなります。*

### プロパティ反映

事前分析を確認した結果、以下の冗長性を特定しました：
- プロパティ1.1と1.2は同じS3イベントトリガーメカニズムをテストするため、1つに統合
- プロパティ3.1と3.2は両方ともDynamoDBへの書き込みをテストするため、包括的なプロパティに統合
- プロパティ4.1、4.2、4.3は全てログ記録をテストするため、1つの包括的なプロパティに統合

### プロパティ 1: CSVファイル読み取りの一貫性
*任意の*有効なCSVファイルについて、S3からの読み取りが成功した場合、ファイル内容はUTF-8エンコーディングで正確に解析される
**検証対象: 要件 1.3, 1.4**

### プロパティ 2: CSV行解析の正確性
*任意の*5つのフィールドを持つCSV行について、解析処理は各フィールドを正しい位置とデータ型で抽出する
**検証対象: 要件 2.2, 2.4**

### プロパティ 3: データ永続化の完全性
*任意の*有効なCSVデータについて、DynamoDBへの書き込みが成功した場合、保存されたアイテムは元のCSVデータと同じCityId、CityName、WeatherName、RainfallProbabilityを含む
**検証対象: 要件 3.1, 3.2**

### プロパティ 4: 処理カウントの正確性
*任意の*CSVファイルについて、処理完了時の成功レコード数は実際にDynamoDBに書き込まれたアイテム数と一致する
**検証対象: 要件 3.3, 3.5**

### プロパティ 5: エラー処理の継続性
*任意の*無効な行を含むCSVファイルについて、無効な行がスキップされても、有効な行の処理は継続される
**検証対象: 要件 2.3, 2.5, 3.4**

### プロパティ 6: ログ記録の包括性
*任意の*CSV処理について、処理開始、エラー詳細、処理統計が適切にログに記録される
**検証対象: 要件 4.1, 4.2, 4.3**

### プロパティ 7: 環境設定の動的取得
*任意の*環境変数設定について、Lambda関数はTABLE_NAME環境変数から正しいテーブル名を取得する
**検証対象: 要件 5.2**

## エラーハンドリング

### エラー分類と対応
1. **ファイルアクセスエラー**
   - S3オブジェクトが存在しない
   - 権限不足
   - 対応: 詳細ログ記録、処理停止

2. **CSV解析エラー**
   - 無効な行形式（フィールド数不足）
   - データ型変換失敗
   - 対応: 行スキップ、エラーログ記録、処理継続

3. **データベースエラー**
   - DynamoDB書き込み失敗
   - テーブル接続エラー
   - 対応: 行スキップ、エラーログ記録、処理継続

4. **システムエラー**
   - メモリ不足
   - タイムアウト
   - 対応: 例外発生、処理停止

## テスト戦略

### 二重テストアプローチ

システムは単体テストとプロパティベーステストの両方を使用して包括的なカバレッジを提供します：

**単体テスト**は以下をカバーします：
- 特定の例とエッジケースの動作確認
- コンポーネント間の統合ポイント
- エラー条件の具体的なケース

**プロパティベーステスト**は以下をカバーします：
- 全ての入力に対して成り立つべき普遍的プロパティ
- ランダムな入力データでの動作検証
- 最小100回の反復実行による徹底的なテスト

**プロパティベーステストライブラリ**: Python用のHypothesisライブラリを使用

**テスト設定要件**:
- 各プロパティベーステストは最小100回の反復実行
- 各テストは対応する設計書のプロパティを明示的に参照
- タグ形式: `**Feature: csv-data-ingestion, Property {number}: {property_text}**`
- 各正確性プロパティは単一のプロパティベーステストで実装